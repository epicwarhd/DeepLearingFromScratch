{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOXajx4/GDc6/2Wd0lDcbSm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"x0M2r2mNiUCF","executionInfo":{"status":"ok","timestamp":1666875998822,"user_tz":-420,"elapsed":2779,"user":{"displayName":"hải lê","userId":"12579717467057317226"}}},"outputs":[],"source":["import tensorflow as tf\n","from keras.layers import Conv2D, Input, Dense, BatchNormalization, MaxPool2D, GlobalAvgPool2D, Flatten, AveragePooling2D, ReLU, Add, ZeroPadding2D\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","import numpy as np"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wRwxYcV-i7K1","executionInfo":{"status":"ok","timestamp":1666876031102,"user_tz":-420,"elapsed":29273,"user":{"displayName":"hải lê","userId":"12579717467057317226"}},"outputId":"cfdebedc-8a2a-4af8-878a-317400a045f1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["!unzip gdrive/MyDrive/Dataset/GTSRB/test.zip > /dev/null\n","!unzip gdrive/MyDrive/Dataset/GTSRB/train.zip > /dev/null\n","!unzip gdrive/MyDrive/Dataset/GTSRB/val.zip > /dev/null"],"metadata":{"id":"tz1YWh4ei8kk","executionInfo":{"status":"ok","timestamp":1666876057023,"user_tz":-420,"elapsed":16294,"user":{"displayName":"hải lê","userId":"12579717467057317226"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def create_generator(batch_size):\n","    train_preprocessor = ImageDataGenerator(\n","        rescale=1 / 255\n","    )\n","\n","    train_generator = train_preprocessor.flow_from_directory(\n","        '/content/train',\n","        class_mode='categorical',\n","        target_size=(60, 60),\n","        color_mode='rgb',\n","        shuffle=True,\n","        batch_size=batch_size\n","    )\n","\n","    val_generator = train_preprocessor.flow_from_directory(\n","        '/content/val',\n","        class_mode='categorical',\n","        target_size=(60, 60),\n","        color_mode='rgb',\n","        shuffle=False,\n","        batch_size=batch_size\n","    )\n","\n","    test_generator = train_preprocessor.flow_from_directory(\n","        '/content/Test',\n","        class_mode='categorical',\n","        target_size=(60, 60),\n","        color_mode='rgb',\n","        shuffle=False,\n","        batch_size=batch_size\n","    )\n","\n","    return train_generator, val_generator, test_generator"],"metadata":{"id":"F97YuDPqipA1","executionInfo":{"status":"ok","timestamp":1666876063391,"user_tz":-420,"elapsed":485,"user":{"displayName":"hải lê","userId":"12579717467057317226"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def identity_block(x, filters):\n","    x_shortcut = x\n","    f1, f2, f3 = filters\n","\n","    x = Conv2D(filters=f1, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n","    x = BatchNormalization()(x)\n","    x = ReLU()(x)\n","\n","    x = Conv2D(filters=f2, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = ReLU()(x)\n","\n","    x = Conv2D(filters=f3, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n","    x = BatchNormalization()(x)\n","\n","    x = Add()([x, x_shortcut])\n","    x = ReLU()(x)\n","\n","    return x\n","\n","\n","def convolutional_block(x, filters, s):\n","    x_shortcut = x\n","    f1, f2, f3 = filters\n","\n","    x = Conv2D(filters=f1, kernel_size=(1, 1), strides=(s, s), padding='valid')(x)\n","    x = BatchNormalization()(x)\n","    x = ReLU()(x)\n","\n","    x = Conv2D(filters=f2, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = ReLU()(x)\n","\n","    x = Conv2D(filters=f3, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n","    x = BatchNormalization()(x)\n","\n","    x_shortcut = Conv2D(filters=f3, kernel_size=(1, 1), strides=(s, s), padding='valid')(x_shortcut)\n","    x_shortcut = BatchNormalization()(x_shortcut)\n","\n","    x = Add()([x, x_shortcut])\n","    x = ReLU()(x)\n","\n","    return x\n","\n","\n","def resnet50(input_shape, classes):\n","    my_input = Input(shape=input_shape)\n","\n","    x = ZeroPadding2D(padding=(3, 3))(my_input)\n","\n","    x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n","    x = BatchNormalization()(x)\n","    x = ReLU()(x)\n","    x = MaxPool2D(pool_size=(3, 3), strides=(2, 2))(x)\n","\n","    x = convolutional_block(x, (64, 64, 256), 1)\n","    x = identity_block(x, (64, 64, 256))\n","    x = identity_block(x, (64, 64, 256))\n","\n","    x = convolutional_block(x, (128, 128, 512), 2)\n","    x = identity_block(x, (128, 128, 512))\n","    x = identity_block(x, (128, 128, 512))\n","    x = identity_block(x, (128, 128, 512))\n","\n","    x = convolutional_block(x, (256, 256, 1024), 2)\n","    x = identity_block(x, (256, 256, 1024))\n","    x = identity_block(x, (256, 256, 1024))\n","    x = identity_block(x, (256, 256, 1024))\n","    x = identity_block(x, (256, 256, 1024))\n","    x = identity_block(x, (256, 256, 1024))\n","\n","    x = convolutional_block(x, (512, 512, 2048), 2)\n","    x = identity_block(x, (512, 512, 2048))\n","    x = identity_block(x, (512, 512, 2048))\n","\n","    x = AveragePooling2D(pool_size=(2, 2))(x)\n","    x = Flatten()(x)\n","    x = Dense(classes, activation='softmax')(x)\n","\n","    model = tf.keras.Model(inputs=my_input, outputs=x)\n","\n","    return model"],"metadata":{"id":"wassVcE5ikZZ","executionInfo":{"status":"ok","timestamp":1666876067290,"user_tz":-420,"elapsed":2,"user":{"displayName":"hải lê","userId":"12579717467057317226"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","epochs = 10\n","\n","train_generator, val_generator, test_generator = create_generator(batch_size)\n","\n","model = resnet50(train_generator.image_shape, train_generator.num_classes)\n","# model.summary()\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.fit(train_generator, epochs=10, batch_size=32, validation_data=val_generator)"],"metadata":{"id":"rA1xysE_itEd"},"execution_count":null,"outputs":[]}]}